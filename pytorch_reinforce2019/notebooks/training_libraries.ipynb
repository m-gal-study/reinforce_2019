{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-level training libraries\n",
    "\n",
    "Writing the training loop is my least favourite thing about PyTorch.\n",
    "\n",
    "Keras is great here!\n",
    "```python\n",
    "model.compile(optimizer, criterion, metrics=[\"accuracy\", \"f1\"])\n",
    "model.fit(X, y, epochs=10)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init, helpers, utils, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import utils  # little helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    get_model,\n",
    "    get_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Contenders\n",
    "## [Ignite](https://github.com/pytorch/ignite)\n",
    "> Ignite is a high-level library to help with training neural networks in PyTorch.\n",
    "> - ignite helps you write compact but full-featured training loops in a few lines of code\n",
    "> - you get a training loop with metrics, early-stopping, model checkpointing and other features without the boilerplate\n",
    "\n",
    "\n",
    "## [TNT](https://github.com/pytorch/tnt)\n",
    "> TNT is a library providing powerful dataloading, logging and visualization utlities for Python. It is closely intergrated with PyTorch and is designed to enable rapid iteration with any model or training regimen.\n",
    "> [...]\n",
    "> The project was inspired by TorchNet, and legend says that it stood for “TorchNetTwo”\n",
    "\n",
    "\n",
    "## [Skorch](https://github.com/dnouri/skorch)\n",
    "> A scikit-learn compatible neural network library that wraps PyTorch.\n",
    "\n",
    "\n",
    "## [PyToune](https://pytoune.org/)\n",
    "> PyToune is a Keras-like framework for PyTorch and handles much of the boilerplating code needed to train neural networks.\n",
    "\n",
    "\n",
    "## [fast.ai](https://docs.fast.ai/)\n",
    "> The fastai library simplifies training fast and accurate neural nets using modern best practices. It's based on research in to deep learning best practices undertaken at fast.ai, including \"out of the box\" support for vision, text, tabular, and collab (collaborative filtering) models.\n",
    "\n",
    "\n",
    "## [MagNet](https://github.com/MagNet-DL/magnet)\n",
    "> MagNet is a high-level Deep Learning API, wrapped around PyTorch.\n",
    "> \n",
    "> It was developed with the aim of reducing boilerplate code and writing Deep Learning architectures with more grace.\n",
    "\n",
    "```python\n",
    "model = nn.Sequential(mn.Conv(32), *mn.Conv() * 2, mn.Linear(10, act=None))\n",
    "```\n",
    "\n",
    "## \"The Fun of Reinvention\"\n",
    "Clearly, there must be a better way! Write your own lib (but don't use it) :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignite Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ignite\n",
    "from ignite.metrics import (\n",
    "    CategoricalAccuracy,\n",
    "    Loss,\n",
    "    Precision,\n",
    ")\n",
    "from ignite.engine import (\n",
    "    create_supervised_evaluator,\n",
    "    create_supervised_trainer,\n",
    "    Events,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss, optimizer\n",
    "model = get_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    utils.get_trainable(model.parameters()),\n",
    "    lr=0.001,\n",
    "    momentum=.9,\n",
    ")\n",
    "\n",
    "# trainer and evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=DEVICE)\n",
    "evaluator = create_supervised_evaluator(\n",
    "    model,\n",
    "    metrics={\n",
    "        \"accuracy\": CategoricalAccuracy(),\n",
    "        \"loss\": Loss(criterion),\n",
    "        \"precision\": Precision(),\n",
    "    },\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    print(\n",
    "        f\"Epoch[{engine.state.epoch}] \"\n",
    "        f\"Batch[{engine.state.iteration}] \"\n",
    "        f\"Loss: {engine.state.output:.2f}\"\n",
    "    )\n",
    "\n",
    "# trainer.run(train_dl, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\n",
    "        f\"Training Results   - Epoch: {trainer.state.epoch}  \"\n",
    "        f\"accuracy: {metrics['accuracy']:.2f} \"\n",
    "        f\"loss: {metrics['loss']:.2f} \"\n",
    "        f\"prec: {metrics['precision'].cpu()}\"\n",
    "    )\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(val_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\n",
    "        f\"Validation Results - Epoch: {trainer.state.epoch}  \"\n",
    "        f\"accuracy: {metrics['accuracy']:.2f} \"\n",
    "        f\"loss: {metrics['loss']:.2f} \"\n",
    "        f\"prec: {metrics['precision'].cpu()}\"\n",
    "    )\n",
    "\n",
    "\n",
    "trainer.run(train_dl, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "- Try out PyToune.\n",
    "- Try out another library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytoune\n",
    "from pytoune.framework import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = get_data()\n",
    "\n",
    "module = get_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    utils.get_trainable(module.parameters()),\n",
    "    lr=0.001,\n",
    "    momentum=.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need two lines of code\n",
    "# model = Model(...)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization with Tensorboard\n",
    "- https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard\n",
    "- https://github.com/lanpa/tensorboard-pytorch\n",
    "\n",
    "![](img/tensorboardx_demo.gif)\n",
    "\n",
    "Make sure tensorboard and tensorboardx are installed:\n",
    "```\n",
    "pip install tensorflow tensorboardx\n",
    "```\n",
    "\n",
    "\n",
    "Start tensorboard:\n",
    "```\n",
    "cd notebooks\n",
    "tensorboard --logdir=tf_log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r tf_log/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls tf_log/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "summary_writer = SummaryWriter(log_dir=f\"tf_log/demo_{random.randint(0, 1000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls tf_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some scalars\n",
    "for i in range(10):\n",
    "    summary_writer.add_scalar(\"training/loss\", np.random.rand(), i)\n",
    "    summary_writer.add_scalar(\"validation/loss\", np.random.rand() + .1, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then visit http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph/network\n",
    "X, _ = next(iter(train_dl))\n",
    "summary_writer.add_graph(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tensorboard with ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new SummaryWriter for new experiment\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "summary_writer = SummaryWriter(log_dir=f\"tf_log/exp_ignite_{now}\")\n",
    "\n",
    "# Basic setup: model, loss, optimizer\n",
    "model = get_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(get_trainable(model.parameters()), lr=0.0001, momentum=.9)\n",
    "\n",
    "# trainer and evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(\n",
    "    model,\n",
    "    metrics={\"accuracy\": CategoricalAccuracy(), \"loss\": Loss(criterion)},\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    epoch = trainer.state.epoch\n",
    "    summary_writer.add_scalar(\"training/accuracy\", metrics['accuracy'], epoch)\n",
    "    summary_writer.add_scalar(\"training/loss\", metrics['loss'], epoch)\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(val_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    epoch = trainer.state.epoch\n",
    "    summary_writer.add_scalar(\"validation/accuracy\", metrics['accuracy'], epoch)\n",
    "    summary_writer.add_scalar(\"validation/loss\", metrics['loss'], epoch)\n",
    "    print(metrics['accuracy'])\n",
    "\n",
    "\n",
    "trainer.run(train_dl, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization with Visdom\n",
    "https://github.com/facebookresearch/visdom\n",
    "![](img/visdom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "- Use visdom with ignite.\n",
    "- Use visdom with any other library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
